{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'KoBertTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4' # nvidia-smi로 비어있는 gpu 확인하고 여기서 선택할것!\n",
    "\n",
    "import re\n",
    "\n",
    "from transformers import (\n",
    "    PreTrainedTokenizerFast as BaseGPT2Tokenizer,\n",
    "    EncoderDecoderModel,\n",
    "    DataCollatorForSeq2Seq,\n",
    ")\n",
    "\n",
    "\n",
    "from asset.tokenization_kobert import KoBertTokenizer\n",
    "from asset import tokenization_kobert\n",
    "src_tokenizer = KoBertTokenizer.from_pretrained('monologg/kobert')\n",
    "\n",
    "#from huggingface_hub import notebook_login\n",
    "\n",
    "#notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2Tokenizer(BaseGPT2Tokenizer):\n",
    "    def build_inputs_with_special_tokens(self, token_ids, _):\n",
    "        return token_ids + [self.eos_token_id]\n",
    "trg_tokenizer = GPT2Tokenizer.from_pretrained(\"skt/kogpt2-base-v2\",\n",
    "  bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
    "  pad_token='<pad>', mask_token='<mask>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EncoderDecoderModel.from_pretrained('./save_points/dacon-v4/checkpoint-276000')\n",
    "model.eval()\n",
    "model.config.decoder_start_token_id = trg_tokenizer.bos_token_id\n",
    "\n",
    "# dacon-v4부터 augmentation 적용됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer # SentenceTransformer Version 2.2.2\n",
    "import pandas as pd\n",
    "\n",
    "# Embedding Vector 추출에 활용할 모델(distiluse-base-multilingual-cased-v1) 불러오기\n",
    "smodel = SentenceTransformer('distiluse-base-multilingual-cased-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 예시\n",
    "preds = [\n",
    "    \"이번 경진대회는 질의 응답 처리를 수행하는 AI 모델을 개발해야합니다.\",\n",
    "    \"데이콘은 플랫폼입니다.\"\n",
    "]\n",
    "\n",
    "gts = [\n",
    "    \"이번 경진대회의 주제는 도배 하자 질의 응답 AI 모델 개발입니다.\",\n",
    "    \"데이콘은 국내 최대의 AI 경진대회 플랫폼입니다.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플에 대한 Cosine Similarity 산식\n",
    "def cosine_similarity(a, b):\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    return dot_product / (norm_a * norm_b) if norm_a != 0 and norm_b != 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 :  이번 경진대회는 질의 응답 처리를 수행하는 AI 모델을 개발해야합니다.\n",
      "정답 :  이번 경진대회의 주제는 도배 하자 질의 응답 AI 모델 개발입니다.\n",
      "Cosine Similarity Score :  0.83436465\n",
      "--------------------\n",
      "예측 :  데이콘은 플랫폼입니다.\n",
      "정답 :  데이콘은 국내 최대의 AI 경진대회 플랫폼입니다.\n",
      "Cosine Similarity Score :  0.6281873\n",
      "--------------------\n",
      "전체 샘플의 Cosine Similarity Score 평균 :  0.731276\n"
     ]
    }
   ],
   "source": [
    "sample_scores = []\n",
    "for pred, gt in zip(preds, gts):\n",
    "    # 생성된 답변 내용을 512 Embedding Vector로 변환\n",
    "    pred_embed = smodel.encode(pred)\n",
    "    gt_embed = smodel.encode(gt)\n",
    "    \n",
    "    sample_score = cosine_similarity(gt_embed, pred_embed)\n",
    "    # Cosine Similarity Score가 0보다 작으면 0으로 간주\n",
    "    sample_score = max(sample_score, 0)\n",
    "    print('예측 : ', pred)\n",
    "    print('정답 : ', gt)\n",
    "    print('Cosine Similarity Score : ', sample_score)\n",
    "    print('-'*20)\n",
    "    sample_scores.append(sample_score)\n",
    "print('전체 샘플의 Cosine Similarity Score 평균 : ', np.mean(sample_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = []\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"./bigdata/train.csv\")\n",
    "input_dict = {\"utterance\":[]}\n",
    "for _, row in data.iterrows():\n",
    "    for q_col in ['질문_1', '질문_2']:\n",
    "        for a_col in ['답변_1', '답변_2', '답변_3', '답변_4', '답변_5']:\n",
    "            input_list.append({\"question\":row[q_col],\"answer\":row[a_col]})\n",
    "data = pd.read_csv('./bigdata/augs_preprocessing/qa_aug.csv')\n",
    "for _, row in data.iterrows():\n",
    "    input_list.append({\"question\":row['Question'],\"answer\":row['Answer']})\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input(path):\n",
    "    test_question = []\n",
    "    test = pd.read_csv(path)\n",
    "    for ut in test['질문']:\n",
    "        test_question.append(ut)\n",
    "\n",
    "    return test_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_q= read_input('./bigdata/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_q_embed = []\n",
    "\n",
    "for gt_q_dic in input_list:\n",
    "    gt_q_embed.append({\"question_embed\":smodel.encode(gt_q_dic[\"question\"]),\"question\":gt_q_dic[\"question\"],\"answer\":gt_q_dic[\"answer\"]})\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def translate(text):\n",
    "    max_sim_dic = {\"question_embed\":None,\"question\":None,\"answer\":None}\n",
    "    max_sim = -100\n",
    "    text_embed = smodel.encode(text)\n",
    "    for gt_dic in gt_q_embed:\n",
    "        tmp_sim = cosine_similarity(gt_dic[\"question_embed\"], text_embed)\n",
    "        if tmp_sim > max_sim:\n",
    "            if \"장점\" or \"단점\" in text:\n",
    "                if (\"장점\" in text and \"단점\" in gt_dic[\"question\"]) or (\"단점\" in text and \"장점\" in gt_dic[\"question\"]):\n",
    "                    #print(\"there was an error\")\n",
    "                    continue\n",
    "            max_sim = tmp_sim\n",
    "            max_sim_dic = {\"question_embed\":gt,\"question\":gt_dic[\"question\"],\"answer\":gt_dic[\"answer\"]}\n",
    "    \n",
    "    \n",
    "    if max_sim < 0.9:\n",
    "        \n",
    "        embeddings = src_tokenizer(text, return_attention_mask=False, return_token_type_ids=False, return_tensors='pt')\n",
    "        embeddings = {k: v for k, v in embeddings.items()}\n",
    "        # generate 함수에 하이퍼파라미터 추가\n",
    "        output_sequences = model.generate(\n",
    "            **embeddings,\n",
    "            max_length=65,\n",
    "            temperature=0.9,\n",
    "            top_k=1,\n",
    "            top_p=0.9,\n",
    "            repetition_penalty=1.2,\n",
    "            do_sample=True,\n",
    "            num_return_sequences=1\n",
    "        )\n",
    "        tmp = trg_tokenizer.decode(output_sequences[0, 1:-1].cpu())\n",
    "        return tmp\n",
    "\n",
    "        # dot postprocessing\n",
    "#         output_sequences = model.generate(\n",
    "#             **embeddings,\n",
    "#             max_length=65,\n",
    "#             temperature=0.9,\n",
    "#             top_k=1,\n",
    "#             top_p=0.9,\n",
    "#             repetition_penalty=1.2,\n",
    "#             do_sample=True,\n",
    "#             num_return_sequences=1\n",
    "#         )\n",
    "        \n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "#         tmp = trg_tokenizer.decode(output_sequences[0, 1:-1].cpu())\n",
    "        \n",
    "#         last_period_index = tmp.rfind('.')\n",
    "        \n",
    "#         sliced_text = \"\"\n",
    "        \n",
    "#         if last_period_index != -1:  # 마침표가 문자열에 존재하는 경우\n",
    "#             sliced_text = tmp[:last_period_index + 1]\n",
    "#         else:  # 마침표가 없는 경우\n",
    "#             sliced_text = tmp\n",
    "        \n",
    "#         return sliced_text\n",
    "    \n",
    "    #print(\"max_sim is...  \" +str(max_sim))\n",
    "    return max_sim_dic[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_framework(text):\n",
    "    pred = \"\"\n",
    "    dividers = [\"또한,\",\"그리고\"]# 며,    . \n",
    "    special_divider1 = [\"와 \",\"관계는 무엇인가요?\"]\n",
    "    for divider in dividers:\n",
    "        \n",
    "        if divider in text:\n",
    "            text1 = text.split(divider)[0].strip()\n",
    "            text2 = text.split(divider)[1].strip()\n",
    "            pred = translate(text1) +\" \"+divider+\" \"+ translate(text2)\n",
    "            return pred\n",
    "    \n",
    "    \n",
    "    \n",
    "    if special_divider1[1] in text:\n",
    "        text1 = text.split(special_divider1[0])[0].strip()\n",
    "        text2 = text.split(special_divider1[0])[1].strip()[:-12]\n",
    "        pred = translate(text1) +\" \"+divider+\" \"+ translate(text2)\n",
    "        return pred\n",
    "    \n",
    "    pred = translate(text)\n",
    "    return pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def translate_framework(text):\n",
    "#     dividers = [\"또한,\", \"그리고\"]  # 일반 구분자\n",
    "#     special_divider = (\"와 \", \"관계는 무엇인가요?\")  # 특별 구분자\n",
    "\n",
    "#     # 특별 구분자에 대해 텍스트를 먼저 검사하고 처리합니다.\n",
    "#     if special_divider[1] in text:\n",
    "#         parts = text.split(special_divider[1])\n",
    "#         for i, part in enumerate(parts[:-1]):  # 마지막 부분 제외\n",
    "#             if special_divider[0] in part:\n",
    "#                 subparts = part.rsplit(special_divider[0], 1)  # 마지막 '와 '로 나눕니다.\n",
    "#                 parts[i] = translate(subparts[0]) + special_divider[0] + translate(subparts[1])\n",
    "#             else:\n",
    "#                 parts[i] = translate(part)\n",
    "#         text = special_divider[1].join(parts)\n",
    "\n",
    "#     # 일반 구분자에 대한 처리\n",
    "#     # 모든 구분자를 하나의 패턴으로 결합합니다.\n",
    "#     pattern = '|'.join(map(re.escape, dividers))\n",
    "#     pieces = re.split(pattern, text)\n",
    "#     translations = [translate(piece) for piece in pieces]\n",
    "\n",
    "#     # 구분자를 기준으로 원본 텍스트에서 구분자들을 추출합니다.\n",
    "#     divider_matches = re.findall(pattern, text)\n",
    "\n",
    "#     # 번역된 부분과 구분자를 다시 조합합니다.\n",
    "#     result = translations[0]\n",
    "#     for divider, translation in zip(divider_matches, translations[1:]):\n",
    "#         result += divider + translation\n",
    "\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leadawon5/gitfiles/venvs/myvenv/lib/python3.7/site-packages/transformers/generation/utils.py:1260: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  \"You have modified the pretrained model configuration to control generation. This is a\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_text :  몰딩 수정을 예방하기 위해 건물 내부에서 어떤 종류의 환경 관리가 필요한가요?\n",
      "result :       몰딩이 햇빛, 습기, 화학물질에 노출될 경우, UV 보호 코팅이나 방수 처리를 통해 몰딩을 보호할 수 있습니다. 습기에 강한 마감재를 사용하거나, 화학물질에 저항력이 있는 소재를 선택하는 것도 중요합니다.\n",
      "\n",
      "\n",
      "source_text :  KMEW 세라믹 지붕재의 단점에 대해 알려주세요. 또한, 세라믹 타일을 사용할 때 고려해야 할 단점은 무엇인가요?\n",
      "result :       KMEW 세라믹 지붕재의 단점 중 하나는 가격이 비싸다는 것입니다. 또 다른 단점으로는 금속 지붕재에 비해 상대적으로 무겁다는 점이 있습니다. 그러나 이러한 단점에도 불구하고, KMEW 세라믹 지붕재는 탁월한 내구성과 아름다운 디자인으로 많은 사람들에게 인기가 있습니다. 또한, 세라믹 타일을 사용할 때는 온도 변화에 민감하며, 내장용으로만 적합하고, 경도가 약해 충격과 마모에 취약하다는 주요 단점을 고려해야 하며, 특히 바닥이나 벽면 사용 시 미끄러울 수 있어 주의가 필요합니다.\n",
      "\n",
      "\n",
      "source_text :  줄퍼티 마감은 무엇인가요? 또한, 액체방수공사는 무엇을 하는 것인가요?\n",
      "result :       줄퍼티 마감은 석고보드의 이음메 부분을 메꾼 후 1차, 2차로 퍼티를 해 마감하는 것을 의미합니다. 줄퍼티 마감은 올퍼티 마감보다 단가가 저렴하다는 장점이 있지만 이음메 부분의 배부름 현상이 있으며, 줄퍼티를 한 곳과 하지 않은 곳의 질감 차이가 있다는 단점이 있어 가게, 식당, 공장에 주로 시공합니다. 또한, 액체방수공사란 콘크리트, 모르타르 등의 표면에 액체 형태의 방수제를 도포하거나 침투시키고 방수제를 혼합한 모르타르를 덧발라 침투를 막는 공법입니다.\n",
      "\n",
      "\n",
      "source_text :  페인트 하도재 없이 페인트를 바로 칠할 경우 어떤 문제가 발생할 수 있나요?\n",
      "result :       페인트 하도재는 바탕면과 페인트의 접착 성능을 높이기 위해 칠합니다. 가장 재료 가까이 칠하기 때문에 상황에 따라 방청(녹방지) 기능이나 방수 기능 등이 포함되어 있는 제품을 칠하기도 합니다. 하도재 없이 바로 칠할 경우 도막의 내구성이 약해져 오래 지나지 않아 페인트 칠이 벗겨질 수 있습니다.\n",
      "\n",
      "\n",
      "source_text :  바닥재가 남으면 어떻게 처리하는 게 좋을까요? 그리고 장판이 남을 때 어떻게 처리해야 하나요?\n",
      "result :       나무재질의 바닥재를 처리하는 방법은 특수 규격 봉투(불연성 폐기물 마대)에 넣어서 배출하면 됩니다. 단, 특수 규격 봉투를 판매하는 곳이 많지 않으니 거주하고 지역의 구청이나 주민센터에 사전문의하는 것이 좋으며 5t 이상의 양은 전문 업체를 통해서 수거해야 합니다. 그리고 장판 처리방법은 구청, 주민센터에서 생활폐기물 스티커를 구매 후 배출해야 합니다. 단, 장판은 크기마다 비용이 다르므로 사전에 크기를 확인해야 합니다.\n",
      "\n",
      "\n",
      "source_text :  도배지에 생긴 반점을 없애기 위해 가장 효과적인 방법은 무엇인가요?\n",
      "result :       벽지에 반점이 생긴 후 보수 방법으로는 반점이 발생한 원인을 정확히 파악한 후 적절한 청소 방법을 선택하는 것이 중요합니다. 가소제 변경으로 인한 반점의 경우, 전문가의 도움을 받아 해당 부분을 청소하거나 필요한 경우 부분적으로 도배지를 교체해야 할 수도 있습니다.\n",
      "\n",
      "\n",
      "source_text :  새집증후군의 주요 원인은 무엇인가요?\n",
      "result :       새집증후군의 주요 원인은 신축 또는 리모델링, 인테리어 공사 등 후에 발생하는 유해한 휘발성 물질에 의해 실내공기가 오염되어, 눈과 목에 통증이 생기거나 두통, 천식, 아토피성피부염 등의 질환이 발생하는 것입니다.\n",
      "\n",
      "\n",
      "source_text :  방청도료 도장 작업을 위해 필요한 단계는 무엇인가요? 또한, 콘크리트 벽에 구멍을 뚫는 방법에는 어떤 도구나 기술을 사용해야 하나요?\n",
      "result :       방청도료 도장 작업은 좁은 부분은 붓을 사용하고, 큰 부분은 스프레이를 사용하여 진행합니다. 방청도료를 사용할 때에는 일반적으로 2~3회에 걸쳐 도장을 하며, 방청 도료의 종류와 해당 도료의 사용법에 따라서 적절한 시간을 두고 완전히 건조한 후에 페인트 작업을 진행하게 됩니다. 또한, 콘크리트에 구멍을 뚫으려면 먼저 사용할 도구를 선택해야 합니다. 작은 구멍의 경우 햄머 드릴과 모음드릴을 사용할 수 있고, 대형 구멍의 경우 코어드릴을 사용하는 것이 효율적일 수 있습니다. 코어드릴이나 해머 드릴과 함께 콘크리트 구멍을 뚫기 위한 전용 드릴 비트가 필요합니다.\n",
      "\n",
      "\n",
      "source_text :  어떤 종류의 실내 식물을 선택해야 식물을 효과적으로 가꾸는 데 도움이 될까요? 그리고 인테리어에 가장 많이 사용되는 도배재료는 무엇인가요?\n",
      "result :       실내 식물을 가꾸려면 자연조명이 있는 곳에 맞는 식물, 공기 정화식물, 그리고 효과적인 관리를 위한 식물을 고려하세요. 그리고 현재 가장 인기 있는 도배 소재는 실크벽지입니다. 실크벽지는 다양한 패턴과 색상이 있으며 유지보수가 쉽고 내구성이 좋아 많은 사람들에게 선호되고 있습니다. 또한 실크벽지는 자연 소재를 사용해 환경에도 더욱 친화적이며 고급스러운 느낌을 줄 수 있는 점도 많은 이용자들에게 인기를 끌고 있습니다.\n",
      "\n",
      "\n",
      "source_text :  원목마루와 롱브릭타일에 대해 설명해주세요. 각각의 단점과 특징은 무엇인가요?\n",
      "result :       원목마루와 다른 마루 재질(예: 라미네이트, 엔지니어드 우드)의 주요 차이점은 재질의 진정성, 내구성, 비용, 그리고 유지 관리의 용이성입니다.\n",
      "\n",
      "\n",
      "source_text :  침실을 더 아늑하게 꾸밀 수 있는 방법에는 어떤 것이 있을까요와 아이가 있는 집을 꾸밀 때 안전을 위해 고려해야 할 요소는 무엇인가요의 관계는 무엇인가요?\n",
      "result :       침실을 아늑하게 만들기 위해서는 부드러운 조명, 포근한 이불과 함께 나무 가구를 활용하는 것이 좋습니다. 뿐만 아니라, 강렬한 색상보다는 부드러운 색감을 활용하고, 공간을 깔끔하게 정리하여 물건들이 과도하게 늘어지거나 밀집되지 않도록 유의해야 합니다. 그리고 아이가 있는 집을 위한 안전하고 실용적인 인테리어를 위해서는 내구성이 좋고 청소하기 쉬운 가구, 안전을 위한 어린이용 매트, 세탁 가능한 러그 등이 필요합니다. 또한 인체에 무해한 친환경적인 소재를 사용한 가구와 장식품을 선택하여 안전성을 높일 수 있습니다.\n",
      "\n",
      "\n",
      "source_text :  인테리어에서 컬러매치를 위한 효과적인 팁이 있을까요? 그리고 복도나 협소한 공간을 확장시키기 위해 가장 효과적인 방법이 무엇일까요?\n",
      "result :       컬러매치를 위해서는 대비 컬러와 조화 컬러를 활용하는 것이 중요합니다. 주요 색상과 보조 색상을 조합하여 공간의 분위기를 조절하고, 색상의 밝고 어두운 정도를 고려하여 조화로운 매치를 만들어야 합니다. 또한, 색채 이론에 따라 웜톤과 쿨톤을 고려하여 컬러를 선택하는 것이 좋습니다. 그리고 복도나 협소한 공간을 확장하려면 큰 거울, 밝은 컬러, 그리고 슬림 가구를 사용하세요. 또한, 거울을 활용하여 공간을 확장하는 효과를 얻을 수 있습니다. 마지막으로, 슬림한 디자인의 가구를 선택하여 적은 공간을 차지하면서도 기능적인 면에서 충분한 효용성을 뽐낼 수 있습니다.\n",
      "\n",
      "\n",
      "source_text :  그라스울 보온판의 주요 장점 중 하나인 흡음 성능은 어떻게 발휘될까요?\"\n",
      "result :       그라스울 보온판의 주요 사용 목적은 건축물의 단열과 흡음을 개선하는 것이며, 주로 세대간 경계벽체, 목조주택의 스터드나 배관 단열용으로 적용됩니다. 불연 재료로서 화재 안전성도 제공하며, 특히 흡음성능을 요구하는 공간에 많이 사용됩니다.\n",
      "\n",
      "\n",
      "source_text :  미네랄울 보온판은 왜 고속 회전원심공법으로 제조되는 건가요?\"\n",
      "result :       미네랄울 보온판은 내화·내열 목적으로 사용될 때, 고온의 환경에서도 변형되지 않고 안정적인 보온 및 보호 기능을 제공합니다. 이는 규산 칼슘계 광석을 고온으로 용융시켜 만든 무기질 섬유의 특성 때문에 가능하며, 불연성이며 열을 효과적으로 차단해 고온에서도 구조물을 보호할 수 있습니다.\n",
      "\n",
      "\n",
      "source_text :  도배 후 필름 시공은 어떤 경우에 추천하시나요? 또한, 낡은 목재 가구의 흠집을 숨기는 방법을 알려주세요.\n",
      "result :       일반적으로 도배 후 필름을 시공하는 것이 일반적입니다. 이유는 벽지 위에 붙은 필름의 부착력이 도배지로 인해 떨어질 수 있기 때문입니다. 미관상의 호불호가 갈리기 때문에 실리콘 마감을 하게 되는데, 필요에 따라 일정을 조절하여 순서를 바꿔서 진행할 수도 있습니다.그러나 일반적인 방법은 도배 후 필름 시공입니다. 또한, 흠집을 목재 펜스틱으로 채우고, 같은 색상의 나무 왁스로 마무리하면 효과적입니다. 또한, 흠집 부분에 목재 접착제를 사용하여 흠집을 메우고 샌드페이퍼로 가볍게 갈아 표면을 매끄럽게 다듬을 수도 있습니다.\n",
      "\n",
      "\n",
      "source_text :  입구나 복도의 표면에 사용하기 적합한 페인트 종류는 무엇이며, 이 공간을 환영스럽게 꾸미는 데 있어 어떤 인테리어 요소가 중요한가요?\n",
      "result :       복도나 입구를 환영적으로 꾸미려면 조명과 수납 공간을 활용하고, 개인적인 터치를 더해야 합니다. 포인트 조명을 활용하여 포근한 분위기를 조성하고, 수납 공간을 효과적으로 활용하여 깔끔한 모습을 유지해야 합니다. 또한, 개인적인 터치를 위해 사진, 그림, 혹은 꽃과 같은 소품을 활용하여 공간을 개성 있게 꾸밀 수 있습니다.\n",
      "\n",
      "\n",
      "source_text :  도배지가 먼지나 연기로 인해 얼마나 빨리 오염될 수 있나요? 그리고 습도가 높을 때 곰팡이가 어떻게 발생하는지 자세히 알고 싶습니다.\n",
      "result :       도배지 표면에 먼지나 연기(담배, 조리과정에서 발생하는 연기 등)가 축적되면 얼룩이 발생할 수 있습니다. 이러한 오염물질은 도배지 표면에 눈에 띄는 얼룩을 형성할 뿐만 아니라 도배지의 색상이 변하거나 표면이 더러워 보일 수 있습니다. 그리고 네, 습도가 높으면 곰팡이가 서식하기 좋은 환경이 되어 곰팡이가 발생할 수 있습니다. 습도 조절을 통해 실내 습도를 적정 수준으로 유지하고 규칙적인 환기를 통해 곰팡이 발생을 예방할 수 있습니다. 또한, 저습도를 유지하고 청소를 규칙적으로 하여 곰팡이 방지에 효과적인 방법입니다.\n",
      "\n",
      "\n",
      "source_text :  방청페인트를 시공하는 방법에는 어떤 단계가 포함되나요? 또한, 배관공사 시 통기구를 설치해야 하는 이유가 무엇인가요?\n",
      "result :       방청페인트의 시공방법은 피도면 정리, 방청도료 도장, 상도작업 순으로 진행합니다. 먼저 피도면을 꼼꼼히 정리하고, 방청도료를 도장한 후 마지막으로 상도작업을 수행합니다. 이러한 순서를 지키면 방청페인트를 효과적으로 시공할 수 있습니다. 또한, 배관공사 시 통기구를 설치하면 악취를 잡을 수 있으며 배수도 원활해집니다.\n",
      "\n",
      "\n",
      "source_text :  유성발수제를 사용하는 것의 실제 효과는 무엇인가요? 또한, 규산질계 침투성 도포 방수공사는 어떤 방식으로 이루어지나요?\n",
      "result :       유성발수제의 장점은 소재에 물의 침투를 차단하여 소재의 수명을 연장하고, 동결, 염에 의한 손상, 화학적 파괴, 생물에 의한 침식 등 다양한 외부 요인에 대해 보호해준다는 점입니다. 이는 건물 구조물이나 소재의 내구성을 향상시켜줄 수 있게 됩니다. 또한, 규산질계 침투성 도포 방수공사는 콘크리트 표면에 무기질의 활성 실리카 성분을 포함한 침투성 물질을 도포하여 콘크리트의 간극 또는 공극에 침투시켜 수밀하게 만들어 방수층을 형성하는 공사입니다.\n",
      "\n",
      "\n",
      "source_text :  높은 습도로 인해 몰딩수정이 발생하는 경우가 있을까요? 또한, 내부와 외부 온도의 큰 차이로 인해 곰팡이 발생이 빨라지나요?\n",
      "result :       고습도 환경에서 몰딩 소재가 팽창하거나 수축하면서 변형될 수 있습니다. 또한, 내외부 온도의 큰 차이는 도배지에 결로를 발생시키고, 이로 인해 곰팡이가 생길 가능성이 있습니다. 따라서 온도차를 줄이고, 제습기를 가동하여 습도를 낮추는 것이 중요합니다. 이를 통해 곰팡이 발생 가능성을 줄일 수 있습니다. 또한, 전문가의 도움을 받아 보수 작업을 진행하는 것이 좋습니다.  1.\n",
      "\n",
      "\n",
      "source_text :  인테리어 소품을 선택할 때 어떤 요소에 주의해야 할까요와 주방을 활기차게 꾸미기 위해 어떤 요소를 추가할 수 있을까요의 관계는 무엇인가요?\n",
      "result :       소품을 선택할 때는 전체적인 분위기와 조화로움을 고려하며, 크기와 색상의 조절을 통해 공간에 균형을 유지하는 것이 중요합니다. 그리고 활기차운 주방을 위해 밝은 컬러 스키마, 식물, 그리고 개방형 수납을 고려해보세요.\n",
      "\n",
      "\n",
      "source_text :  초배지만 남은 벽에 페인트를 칠하면 어떤 문제가 발생하나요? 또한, 속건형 유성 발수제의 사용 목적과 효과에 대해 알려주세요.\n",
      "result :       초배지는 매우 얇아서 고르지 않은 표면이 많아 페인트를 바로 칠할 경우 표면이 부식될 수 있고, 페인트의 부착력이 떨어지기 때문에 페인트를 바로 칠하는 것은 부적절합니다. 따라서 벽에 초배지를 칠한 후 페인트를 칠하는 것이 좋습니다. 또한, 속건형 유성 발수제의 장점은 다양한 건축자재의 표면에 발라 빗물과 기타 물질의 침투를 막아주어 건축자재의 색상을 보호하고 유지시켜주는 것뿐만 아니라 건물의 균열, 백화현상, 그리고 철근의 부식을 방지하여 건축물의 수명을 연장시켜 준다는 것입니다.\n",
      "\n",
      "\n",
      "source_text :  벽지에 반점이 생겼을 때, 왜 1년 이내인 경우에만 벽지 아세톤 용제 함침 방법을 사용하고 개선 벽지로 재시공해야 하나요?\n",
      "result :       벽지에 반점이 생겼을 때 유색반점 발생 시기가 벽지시공 후 1년 이내인 경우, 보수작업은 아래와 같이 해야 합니다. 먼저, 이염 방지제를 도포한 후에 개선 벽지로 전면 재시공하는 것이 필요합니다.\n",
      "\n",
      "\n",
      "source_text :  석구조란 무엇인가요? 그리고 기둥-보 구조 방식은 무엇을 의미하나요?\n",
      "result :       석구조는 석재로 쌓아 올리는 구조로 궁전, 불사, 탑비 등의 고건물에서 볼 수 있는데 풍압력, 지진력, 기타 인위적 횡력에는 극히 약하므로 고층 건물에는 부적절하며 보강구조로 해야 합니다. 그리고 기둥-보 구조 방식은 가장 오래된 목구조 방식 중 하나로 통나무 구조에서 발전된 건축양식입니다. 주로 상업건물이나, 규모가 큰 주택 등에 사용되며 요즘에는 전형적인 플랫폼 구조와 혼용되기도 합니다.\n",
      "\n",
      "\n",
      "source_text :  원목마루의 어떤 단점이 있는지 알려주세요. 그리고 도배지가 남으면 어떻게 처리해야 하나요?\n",
      "result :       강마루는 보수, 철거 비용이 많이 들고 강화마루에 비해 가격이 비싸며 친환경적이지 않다는 단점이 있습니다. 그리고 도배지 처리방법은 폐기물 스티커 부착입니다. 폐기물 스티커은 동사무소, 편의점, 일반 슈퍼 등에서 구매가능하며, 아파트의 경우 경비실에 비치한 경우가 있으니 문의하는 것을 추천합니다.\n",
      "\n",
      "\n",
      "source_text :  마감재의 하자를 판단하는 데 어떤 방법을 사용해야 할까요? 그리고 새집증후군을 예방하는 데 가장 효과적인 방법은 무엇인가요?\n",
      "result :       마감재의 하자 여부를 판단하기 위해서는 몇 가지 요소를 고려해야 합니다. 첫째로는 설계도서와의 일치 여부가 있습니다. 마감재가 설계도서에 명시된 내용과 일치하는지 확인해야 합니다. 둘째로는 기능상의 문제, 예를 들어 마감재가 쉽게 파손되거나 사용상의 문제가 있는지를 확인해야 합니다. 그 다음으로는 미관상의 문제 여부도 중요합니다. 그리고 새집증후군을 예방하는 방법은 실내흡연을 하지않고 포르말린을 사용하지 않은 목재 가구와 휘발성 물질, 화학물질이 함유된 방향제를 사용하지 않으며 공기 청정 식물을 키우고 환기를 자주시켜야 합니다.\n",
      "\n",
      "\n",
      "source_text :  강마루 바닥재의 장점은 무엇인가요?\n",
      "result :       강마루는 표면 내구성이 좋고 디자인이 다양하며 유지 관리가 쉽고 열전도율이 높아 난방효과가 좋으며 소음 발생이 적다는 장점이 있습니다. 또한 강마루는 환경 친화적이며 물에 강한 튼튼한 재질로 제작되어 내구성이 뛰어나다는 장점도 있습니다. 이러한 장점으로 인해 많은 사람들에게 선호되고 있습니다.\n",
      "\n",
      "\n",
      "source_text :  새집증후군을 예방하기 위해 창문을 열어 환기하는 이유는 무엇인가요?\n",
      "result :       새집증후군 예방을 위해 샤워 헤드와 수도꼭지를 선택하실 때에는 포르말린과 같은 유해 물질을 사용하지 않은 제품을 선택하는 것이 좋습니다. 또한, 창문을 열어 자연 환기를 유도하는 것도 도움이 될 수 있습니다. 추가적으로, 실내 식물을 통해 공기 중의 유해 물질을 흡수하는 것도 도움이 될 수 있습니다.\n",
      "\n",
      "\n",
      "source_text :  도배풀을 제거하는 데 어떤 도구가 가장 효과적인가요? 또한, 옥상 방수용 탄성 에멀전 페인트를 사용하는 장점은 무엇인가요?\n",
      "result :       도배 후 바닥이나 몰딩, 벽지에 붙은 도배풀을 제거하려면 걸레로 살살 닦아내야 하며 지워지지 않을 시 도배풀 제거제를 사용해야 합니다. 만약 걸러로 제거가 어렵다면 도배풀 제거제를 사용하여 깔끔하게 제거할 수 있습니다. 또한, 옥상 방수용 탄성 에멀전 페인트는 건조 후 이음매 없이 연속적으로 형성된 도막이 뛰어난 내수성을 갖으며 건물의 충격이나 수축과 팽창에도 도막이 갈라지거나 손상되는 것을 방지하도록 탄성과 인장강도를 보유하며, 침수가 반복되는 장기간의 옥외폭로 조건에서도 소지 부착성과 내구성을 보유한 도료입니다.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "for i in range(len(test_q)):\n",
    "    sr_text = test_q[i] # dialect\n",
    "    tg_text = translate_framework(sr_text) # translate\n",
    "    preds.append(tg_text)\n",
    "    if i>30 and i<60:\n",
    "        print(\"source_text : \",sr_text)\n",
    "        print(\"result :      \",tg_text)\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130, 512)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test 데이터셋의 모든 질의에 대한 답변으로부터 512 차원의 Embedding Vector 추출\n",
    "# 평가를 위한 Embedding Vector 추출에 활용하는 모델은 'distiluse-base-multilingual-cased-v1' 이므로 반드시 확인해주세요.\n",
    "from sentence_transformers import SentenceTransformer # SentenceTransformer Version 2.2.2\n",
    "\n",
    "# Embedding Vector 추출에 활용할 모델(distiluse-base-multilingual-cased-v1) 불러오기\n",
    "model = SentenceTransformer('distiluse-base-multilingual-cased-v1')\n",
    "\n",
    "# 생성한 모든 응답(답변)으로부터 Embedding Vector 추출\n",
    "pred_embeddings = model.encode(preds)\n",
    "pred_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vec_0</th>\n",
       "      <th>vec_1</th>\n",
       "      <th>vec_2</th>\n",
       "      <th>vec_3</th>\n",
       "      <th>vec_4</th>\n",
       "      <th>vec_5</th>\n",
       "      <th>vec_6</th>\n",
       "      <th>vec_7</th>\n",
       "      <th>vec_8</th>\n",
       "      <th>...</th>\n",
       "      <th>vec_502</th>\n",
       "      <th>vec_503</th>\n",
       "      <th>vec_504</th>\n",
       "      <th>vec_505</th>\n",
       "      <th>vec_506</th>\n",
       "      <th>vec_507</th>\n",
       "      <th>vec_508</th>\n",
       "      <th>vec_509</th>\n",
       "      <th>vec_510</th>\n",
       "      <th>vec_511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>0.044602</td>\n",
       "      <td>0.012139</td>\n",
       "      <td>0.020529</td>\n",
       "      <td>0.011162</td>\n",
       "      <td>0.065665</td>\n",
       "      <td>0.020268</td>\n",
       "      <td>-0.018136</td>\n",
       "      <td>0.012876</td>\n",
       "      <td>0.015751</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001223</td>\n",
       "      <td>-0.030352</td>\n",
       "      <td>-0.016536</td>\n",
       "      <td>-0.029630</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.050644</td>\n",
       "      <td>0.025173</td>\n",
       "      <td>0.017702</td>\n",
       "      <td>0.031392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>-0.041642</td>\n",
       "      <td>0.033430</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>-0.009218</td>\n",
       "      <td>0.047056</td>\n",
       "      <td>0.011109</td>\n",
       "      <td>-0.027505</td>\n",
       "      <td>-0.006905</td>\n",
       "      <td>0.005268</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000544</td>\n",
       "      <td>0.018413</td>\n",
       "      <td>-0.040152</td>\n",
       "      <td>-0.019035</td>\n",
       "      <td>0.012574</td>\n",
       "      <td>0.063181</td>\n",
       "      <td>-0.053114</td>\n",
       "      <td>-0.030768</td>\n",
       "      <td>0.009494</td>\n",
       "      <td>0.015076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>0.013767</td>\n",
       "      <td>-0.044200</td>\n",
       "      <td>-0.033360</td>\n",
       "      <td>-0.001521</td>\n",
       "      <td>0.138270</td>\n",
       "      <td>-0.030953</td>\n",
       "      <td>-0.003520</td>\n",
       "      <td>-0.031130</td>\n",
       "      <td>0.031937</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005634</td>\n",
       "      <td>-0.024755</td>\n",
       "      <td>0.046367</td>\n",
       "      <td>-0.023750</td>\n",
       "      <td>-0.014049</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>-0.036908</td>\n",
       "      <td>-0.035307</td>\n",
       "      <td>-0.050996</td>\n",
       "      <td>0.090346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>-0.027219</td>\n",
       "      <td>-0.004336</td>\n",
       "      <td>0.058696</td>\n",
       "      <td>0.006045</td>\n",
       "      <td>0.091306</td>\n",
       "      <td>-0.063706</td>\n",
       "      <td>-0.070253</td>\n",
       "      <td>-0.007821</td>\n",
       "      <td>0.002429</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051810</td>\n",
       "      <td>-0.026638</td>\n",
       "      <td>-0.043167</td>\n",
       "      <td>-0.013853</td>\n",
       "      <td>-0.051651</td>\n",
       "      <td>0.036527</td>\n",
       "      <td>-0.039670</td>\n",
       "      <td>-0.014180</td>\n",
       "      <td>-0.020559</td>\n",
       "      <td>0.095904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>0.001872</td>\n",
       "      <td>0.007149</td>\n",
       "      <td>-0.005232</td>\n",
       "      <td>-0.008722</td>\n",
       "      <td>0.116962</td>\n",
       "      <td>0.005872</td>\n",
       "      <td>0.055559</td>\n",
       "      <td>0.038449</td>\n",
       "      <td>-0.019666</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012512</td>\n",
       "      <td>-0.000370</td>\n",
       "      <td>0.033457</td>\n",
       "      <td>0.007287</td>\n",
       "      <td>-0.025373</td>\n",
       "      <td>0.008964</td>\n",
       "      <td>-0.019305</td>\n",
       "      <td>0.018529</td>\n",
       "      <td>0.008241</td>\n",
       "      <td>0.042715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id     vec_0     vec_1     vec_2     vec_3     vec_4     vec_5  \\\n",
       "0  TEST_000  0.044602  0.012139  0.020529  0.011162  0.065665  0.020268   \n",
       "1  TEST_001 -0.041642  0.033430  0.000083 -0.009218  0.047056  0.011109   \n",
       "2  TEST_002  0.013767 -0.044200 -0.033360 -0.001521  0.138270 -0.030953   \n",
       "3  TEST_003 -0.027219 -0.004336  0.058696  0.006045  0.091306 -0.063706   \n",
       "4  TEST_004  0.001872  0.007149 -0.005232 -0.008722  0.116962  0.005872   \n",
       "\n",
       "      vec_6     vec_7     vec_8  ...   vec_502   vec_503   vec_504   vec_505  \\\n",
       "0 -0.018136  0.012876  0.015751  ... -0.001223 -0.030352 -0.016536 -0.029630   \n",
       "1 -0.027505 -0.006905  0.005268  ... -0.000544  0.018413 -0.040152 -0.019035   \n",
       "2 -0.003520 -0.031130  0.031937  ... -0.005634 -0.024755  0.046367 -0.023750   \n",
       "3 -0.070253 -0.007821  0.002429  ... -0.051810 -0.026638 -0.043167 -0.013853   \n",
       "4  0.055559  0.038449 -0.019666  ... -0.012512 -0.000370  0.033457  0.007287   \n",
       "\n",
       "    vec_506   vec_507   vec_508   vec_509   vec_510   vec_511  \n",
       "0  0.000294  0.014831  0.050644  0.025173  0.017702  0.031392  \n",
       "1  0.012574  0.063181 -0.053114 -0.030768  0.009494  0.015076  \n",
       "2 -0.014049  0.000465 -0.036908 -0.035307 -0.050996  0.090346  \n",
       "3 -0.051651  0.036527 -0.039670 -0.014180 -0.020559  0.095904  \n",
       "4 -0.025373  0.008964 -0.019305  0.018529  0.008241  0.042715  \n",
       "\n",
       "[5 rows x 513 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv('./bigdata/sample_submission.csv')\n",
    "# 제출 양식 파일(sample_submission.csv)을 활용하여 Embedding Vector로 변환한 결과를 삽입\n",
    "submit.iloc[:,1:] = pred_embeddings\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리더보드 제출을 위한 csv파일 생성\n",
    "submit.to_csv('./submit/dacon-v0_submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "myvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
