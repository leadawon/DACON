{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leadawon5/gitfiles/venvs/vpvenv/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import random\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(42) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"neulab/codebert-cpp\"\n",
    "MODEL_TAG = \"neulab_codebert-cpp\"\n",
    "root_dir = \"/home/leadawon5/decs_jupyter_lab/gitfiles/DACON/code_similarity/bigdata/train_code\" \n",
    "\n",
    "class CodeEncoder(nn.Module):\n",
    "    def __init__(self, model_name=MODEL_NAME):\n",
    "        super(CodeEncoder, self).__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return outputs.pooler_output  # Use the pooled output\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeComparisonModel(nn.Module):\n",
    "    def __init__(self, encoder_model_name):\n",
    "        super(CodeComparisonModel, self).__init__()\n",
    "        self.encoder = CodeEncoder(encoder_model_name)\n",
    "        # 두 임베딩을 결합한 후 사용할 추가적인 레이어를 정의합니다.\n",
    "        self.fc = nn.Linear(self.encoder.encoder.config.hidden_size * 2, 1)\n",
    "\n",
    "    def forward(self, input_ids1, attention_mask1, input_ids2, attention_mask2):\n",
    "        embedding1 = self.encoder(input_ids1, attention_mask1)\n",
    "        embedding2 = self.encoder(input_ids2, attention_mask2)\n",
    "        # 두 임베딩을 결합합니다.\n",
    "        combined_embedding = torch.cat((embedding1, embedding2), 1)\n",
    "        # 결합된 임베딩을 추가적인 레이어에 통과시켜 이진 분류를 위한 로짓을 예측합니다.\n",
    "        logits = self.fc(combined_embedding)\n",
    "        # Sigmoid 함수를 적용하여 확률 값으로 변환\n",
    "        probabilities = torch.sigmoid(logits)\n",
    "        return probabilities.squeeze(-1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at neulab/codebert-cpp were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at neulab/codebert-cpp and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CodeComparisonModel(MODEL_NAME).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 epoch is running!: 1it [00:16, 16.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to ./model/neulab_codebert-cpp_checkpoint_epoch_0_step_0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 epoch is running!: 3278it [54:50,  1.06s/it]"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(model, optimizer, filepath):\n",
    "    if os.path.exists(filepath):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        epoch = checkpoint['epoch']\n",
    "        print(f\"Checkpoint loaded from {filepath} at epoch {epoch}\")\n",
    "        return epoch\n",
    "    else:\n",
    "        print(\"No checkpoint found at specified path!\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# 체크포인트 파일 경로 지정\n",
    "checkpoint_path = \"./bigdata/model/checkpoint_epoch_1.pth\"\n",
    "\n",
    "# 체크포인트 불러오기\n",
    "epoch = load_checkpoint(model, optimizer, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(model, tokenizer, text1, text2, device, threshold=0.5):\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    with torch.no_grad():  # 그래디언트 계산을 비활성화\n",
    "        # 두 코드 스니펫을 토큰화하고 디바이스로 이동\n",
    "        inputs1 = tokenizer(text1, return_tensors='pt', max_length=512, padding='max_length', truncation=True)\n",
    "        inputs2 = tokenizer(text2, return_tensors='pt', max_length=512, padding='max_length', truncation=True)\n",
    "        \n",
    "        inputs1 = {k: v.to(device) for k, v in inputs1.items()}\n",
    "        inputs2 = {k: v.to(device) for k, v in inputs2.items()}\n",
    "\n",
    "        # 모델을 통해 유사도 점수(확률) 계산\n",
    "        probabilities = model(**inputs1, **inputs2)\n",
    "\n",
    "        # 유사도 점수를 기반으로 판단\n",
    "        predicted_label = (probabilities > threshold).long()  # 확률이 임계값보다 크면 1, 아니면 0\n",
    "        print(f\"Similarity score: {probabilities.item()}\")\n",
    "        print(f\"Predicted label: {'Same' if predicted_label.item() == 1 else 'Different'}\")\n",
    "\n",
    "# 추론 실행\n",
    "infer(model, tokenizer, code_text1, code_text2, device, threshold=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer와 model은 미리 정의되어 있어야 합니다.\n",
    "# device는 'cuda' 또는 'cpu'일 수 있습니다.\n",
    "\n",
    "def predict(model, tokenizer, test_data, device, threshold=0.5):\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():  # 그래디언트 계산 비활성화\n",
    "        for index, row in tqdm(test_data.iterrows(), total=test_data.shape[0]):\n",
    "            # 코드 쌍을 토큰화합니다.\n",
    "            inputs1 = tokenizer(row['code1'], return_tensors='pt', max_length=512, padding='max_length', truncation=True).to(device)\n",
    "            inputs2 = tokenizer(row['code2'], return_tensors='pt', max_length=512, padding='max_length', truncation=True).to(device)\n",
    "            \n",
    "            # 모델을 통해 유사도 점수(로짓)를 계산합니다.\n",
    "            logits = model(inputs1['input_ids'], inputs1['attention_mask'], inputs2['input_ids'], inputs2['attention_mask'])\n",
    "            \n",
    "            # 로짓을 확률로 변환하기 위해 sigmoid 함수를 적용합니다.\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            \n",
    "            # 설정한 임계값을 기준으로 유사 여부를 판단합니다.\n",
    "            prediction = 1 if probs > threshold else 0\n",
    "            predictions.append(prediction)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# 예제 사용\n",
    "test_data = pd.read_csv(\"./bigdata/test.csv\")\n",
    "# 모델과 tokenizer가 정의되어 있어야 합니다.\n",
    "predictions = predict(model, tokenizer, test_data, device, threshold=0.5)\n",
    "\n",
    "# 결과를 제출 파일로 저장\n",
    "submission = pd.read_csv('./bigdata/sample_submission.csv')\n",
    "submission['similar'] = predictions\n",
    "submission.to_csv('./bigdata/predictions_submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vpvenv",
   "language": "python",
   "name": "vpvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
